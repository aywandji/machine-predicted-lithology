{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 1357,
     "status": "ok",
     "timestamp": 1602782196782,
     "user": {
      "displayName": "Arnaud Yankwa",
      "photoUrl": "",
      "userId": "14841658183693520304"
     },
     "user_tz": -120
    },
    "id": "RHPZbmpwWuqx"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"7\"\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "plt.style.use(\"ggplot\")\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 1548,
     "status": "ok",
     "timestamp": 1602782226215,
     "user": {
      "displayName": "Arnaud Yankwa",
      "photoUrl": "",
      "userId": "14841658183693520304"
     },
     "user_tz": -120
    },
    "id": "XVs_5zswY1Q7",
    "outputId": "37935049-3b90-4179-a4d5-561ef5445d17"
   },
   "outputs": [],
   "source": [
    "data_folder = \"data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 1376,
     "status": "ok",
     "timestamp": 1602782226217,
     "user": {
      "displayName": "Arnaud Yankwa",
      "photoUrl": "",
      "userId": "14841658183693520304"
     },
     "user_tz": -120
    },
    "id": "_fDgkBrCX8R9"
   },
   "outputs": [],
   "source": [
    "from utils import reduce_mem_usage, WellLogsProcessing, plot_features_importance, penalty_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "executionInfo": {
     "elapsed": 6646,
     "status": "ok",
     "timestamp": 1602782231893,
     "user": {
      "displayName": "Arnaud Yankwa",
      "photoUrl": "",
      "userId": "14841658183693520304"
     },
     "user_tz": -120
    },
    "id": "RXlPmFe4Ytfw",
    "outputId": "fa1d1f30-87f6-4ce9-f76f-f7ccf7a008a9"
   },
   "outputs": [],
   "source": [
    "dest_file = data_folder + \"train.csv\"\n",
    "train_df = pd.read_csv(data_folder + \"train.csv\",sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 8358,
     "status": "ok",
     "timestamp": 1602782233830,
     "user": {
      "displayName": "Arnaud Yankwa",
      "photoUrl": "",
      "userId": "14841658183693520304"
     },
     "user_tz": -120
    },
    "id": "o3pmm_z5n6qV",
    "outputId": "49dea313-3bd8-4c9e-95c1-a9abc084f4d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of properties dataframe is : 258.9785385131836  MB\n",
      "******************************\n",
      "Column:  DEPTH_MD\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  X_LOC\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  Y_LOC\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  Z_LOC\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  CALI\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  RSHA\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  RMED\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  RDEP\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  RHOB\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  GR\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  SGR\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  NPHI\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  PEF\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  DTC\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  SP\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  BS\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  ROP\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  DTS\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  DCAL\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  DRHO\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  MUDWEIGHT\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  RMIC\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  ROPA\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  RXO\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  FORCE_2020_LITHOFACIES_LITHOLOGY\n",
      "dtype before:  int64\n",
      "dtype after:  uint32\n",
      "******************************\n",
      "******************************\n",
      "Column:  FORCE_2020_LITHOFACIES_CONFIDENCE\n",
      "dtype before:  float64\n",
      "dtype after:  float32\n",
      "******************************\n",
      "___MEMORY USAGE AFTER COMPLETION:___\n",
      "Memory usage is:  142.884765625  MB\n",
      "This is  55.17243492272094 % of the initial size\n"
     ]
    }
   ],
   "source": [
    "train_df,na = reduce_mem_usage(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "df1Pdp9NdHAi"
   },
   "source": [
    "## Splitting data per well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### get train wells and fit imputer on them\n",
    "###93000 is only in well 16/4-1\n",
    "all_lith  = train_df.FORCE_2020_LITHOFACIES_LITHOLOGY.unique()\n",
    "all_wells  = train_df.WELL.unique()\n",
    "\n",
    "###Keep 4 wells for val/test sets\n",
    "val_wells = [\"16/10-1\",\"16/2-16\"]\n",
    "test_wells = [\"16/11-1 ST3\",\"34/3-1 A\"]\n",
    "train_wells = [well_name for well_name in all_wells if well_name not in val_wells+test_wells]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = train_df.loc[train_df.WELL.isin(train_wells),:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5DTPAp2W_5Nx"
   },
   "source": [
    "## data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features selection have been done from data_analysis notebooks. Those features are either very discriminative or with very few null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = ['RMED', 'RDEP', 'RHOB', 'GR', 'NPHI','DTC','RXO','RSHA',\n",
    "                    \"X_LOC\",\"Y_LOC\",\"Z_LOC\",'DEPTH_MD']\n",
    "# numeric_features = ['RMED', 'RDEP', 'RHOB', 'GR', 'NPHI','DTC',\"X_LOC\",\"Y_LOC\",\"Z_LOC\",'DEPTH_MD']\n",
    "# numeric_features = ['RMED', 'RDEP','DRHO','CALI',\n",
    "#                     'RHOB', 'GR', 'NPHI','DTC',\"DTS\",'PEF','SP','RXO','RSHA',\n",
    "#                     \"RMIC\",\"X_LOC\",\"Y_LOC\",\"Z_LOC\",'DEPTH_MD']\n",
    "\n",
    "cat_features = ['GROUP','FORMATION']\n",
    "\n",
    "others_numeric=[]\n",
    "\n",
    "all_formations = list(full_df.FORMATION.unique())\n",
    "all_formations.remove(np.nan)\n",
    "all_formations = sorted(all_formations)\n",
    "\n",
    "all_groups = list(full_df.GROUP.unique())\n",
    "all_groups.remove(np.nan)\n",
    "all_groups = sorted(all_groups)\n",
    "\n",
    "#### Instanciate Logs Processing pipeline. Here we will only fill numerical empty values\n",
    "logs_processor = WellLogsProcessing(numeric_features ,cat_features ,\n",
    "                                    others_numeric,all_formations ,all_groups,\n",
    "                                    remove_outliers=False,process_num_features=True,\n",
    "                                      impute_categorical = False, encode_categorical=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting iterative imputer\n",
      "[IterativeImputer] Completing matrix with shape (1125622, 12)\n",
      "[IterativeImputer] Change: 103628.125, scaled tolerance: 6856.661 \n",
      "[IterativeImputer] Change: 336598.71875, scaled tolerance: 6856.661 \n",
      "[IterativeImputer] Change: 153881.625, scaled tolerance: 6856.661 \n",
      "[IterativeImputer] Change: 52670.0859375, scaled tolerance: 6856.661 \n"
     ]
    }
   ],
   "source": [
    "######### Numerical features empty values imputation and scaling\n",
    "filled_full_data = logs_processor.get_processed_data(full_df.loc[:,full_df.columns],is_train_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filled_full_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GROUP,FEATURE PREDICTION\n",
    "Now we will predict GROUP AND FORMATION features instead of just imputing them with the mode value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from utils import predict_target, get_predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### GROUP prediction. We define predictors, classifier and we train and predict GROUP feature\n",
    "\n",
    "group_predictors = ['DEPTH_MD', 'X_LOC', 'Y_LOC', 'Z_LOC','RMED', 'RDEP', 'RHOB', 'GR', 'NPHI',\n",
    "                       'DTC',\"RSHA\"]\n",
    "catboost_classifier = CatBoostClassifier(iterations=500,learning_rate=0.1,depth = 4,\n",
    "                                            min_data_in_leaf = 50,\n",
    "                                             bagging_temperature = 10,\n",
    "                                            grow_policy = 'Depthwise',objective='MultiClassOneVsAll',\n",
    "                                            custom_metric = ['Accuracy'],\n",
    "                                            early_stopping_rounds = 100,task_type='GPU',\n",
    "                                            train_dir = data_folder)\n",
    "filled2, group_imputer, group_predictors_scaler = get_predictor(filled_full_data.loc[:,filled_full_data.columns],\n",
    "                                                                  catboost_classifier,\n",
    "                                                                   target='GROUP',regressors=group_predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_features_importance(group_imputer.feature_importances_,group_imputer.feature_names_,figsize=(20,20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We splitted samples having a non null GROUP feature in train/val sets.\n",
    "- After training, our GROUP classifier is accurate at 88% on val set. So we can use it to impute GROUP feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filled2[\"enc_GROUP\"] = filled2.GROUP.map(all_groups.index).astype(int).astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FORMATION prediction. We define predictors, classifier and we train and predict FORMATION feature\n",
    "formation_predictors = ['DEPTH_MD',\"enc_GROUP\", 'X_LOC', 'Y_LOC', 'Z_LOC','RMED', 'RDEP', 'RHOB', 'GR', 'NPHI',\n",
    "                       'DTC',\"RSHA\"]\n",
    "\n",
    "target = \"FORMATION\"\n",
    "cat_1 = formation_predictors.index(\"enc_GROUP\")\n",
    "encoded_cat = [\"enc_GROUP\"]\n",
    "\n",
    "catboost_classifier = CatBoostClassifier(iterations=800,learning_rate=0.1,depth = 4,\n",
    "                                            min_data_in_leaf = 50,\n",
    "                                            bagging_temperature = 10,\n",
    "                                            cat_features = [cat_1],\n",
    "                                            grow_policy = 'Depthwise',objective='MultiClass',\n",
    "                                            custom_metric = ['Accuracy'],\n",
    "                                            early_stopping_rounds = 100,task_type='GPU',\n",
    "                                            train_dir = data_folder)\n",
    "filled3, formation_imputer, formation_predictors_scaler = get_predictor(filled2.loc[:,filled2.columns],\n",
    "                                                                  catboost_classifier,\n",
    "                                                                   target=target,\n",
    "                                                                regressors=formation_predictors,\n",
    "                                                                           encoded_cat=encoded_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_features_importance(formation_imputer.feature_importances_,\n",
    "                         formation_imputer.feature_names_,figsize=(20,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = filled2.FORMATION.notna()\n",
    "num_features = list(set(formation_predictors) - set(encoded_cat))\n",
    "vali  = filled2.loc[mask,num_features]\n",
    "vali[vali.columns] = formation_predictors_scaler.transform(vali)\n",
    "vali[encoded_cat] = filled2.loc[mask,encoded_cat]\n",
    "print(\"Accuracy of FORMATION classifier is : \",accuracy_score(filled2.loc[mask,\"FORMATION\"].values,\n",
    "                                              formation_imputer.predict(vali[formation_predictors])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final step\n",
    "fill null values for train/val/test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##let's fill the whole dataset and save everything\n",
    "filled_whole = logs_processor.get_processed_data(train_df.loc[:,train_df.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##fill GROUP\n",
    "filled_whole2 = filled_whole.loc[:,filled_whole.columns]\n",
    "mask = filled_whole2.GROUP.isna()\n",
    "if mask.any():\n",
    "    vali = group_predictors_scaler.transform(filled_whole2.loc[mask,group_predictors])\n",
    "    filled_whole2.loc[mask,\"GROUP\"] = group_imputer.predict(vali)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## fill FORMATION\n",
    "filled_whole2[\"enc_GROUP\"] = filled_whole2.GROUP.map(lambda x: logs_processor.all_groups.get(x,1000)).astype(int).astype(\"category\")\n",
    "\n",
    "filled_whole3 = filled_whole2.loc[:,filled_whole2.columns]\n",
    "\n",
    "encoded_cat = [\"enc_GROUP\"]\n",
    "num_features = list(set(formation_predictors) - set(encoded_cat))\n",
    "\n",
    "\n",
    "mask = filled_whole3.FORMATION.isna()\n",
    "if mask.any():\n",
    "    vali  = filled_whole3.loc[mask,num_features]\n",
    "    vali[vali.columns] = formation_predictors_scaler.transform(vali)\n",
    "    vali[encoded_cat] = filled_whole3[encoded_cat]\n",
    "    filled_whole3.loc[mask,\"FORMATION\"] = formation_imputer.predict(vali[formation_predictors])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving \n",
    "Now we save processed data and processing pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 851,
     "status": "ok",
     "timestamp": 1602797336388,
     "user": {
      "displayName": "Arnaud Yankwa",
      "photoUrl": "",
      "userId": "14841658183693520304"
     },
     "user_tz": -120
    },
    "id": "daXY5wiFKm9Z"
   },
   "outputs": [],
   "source": [
    " from joblib import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filled_whole3.loc[:,['FORCE_2020_LITHOFACIES_LITHOLOGY','FORCE_2020_LITHOFACIES_CONFIDENCE']] = train_df.loc[:,['FORCE_2020_LITHOFACIES_LITHOLOGY','FORCE_2020_LITHOFACIES_CONFIDENCE']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filled_whole3,na = reduce_mem_usage(filled_whole3.drop(columns=\"enc_GROUP\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### All features are filled. The only exception is FORCE_2020_LITHOFACIES_CONFIDENCE \n",
    "#but it doesn't matter since we are not using \n",
    "filled_whole3.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filled_whole3.to_csv(data_folder+\"filled_train.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs_processor.save_processing_params(data_folder=data_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 879,
     "status": "ok",
     "timestamp": 1602797585564,
     "user": {
      "displayName": "Arnaud Yankwa",
      "photoUrl": "",
      "userId": "14841658183693520304"
     },
     "user_tz": -120
    },
    "id": "yi6nNZ67Y6gM"
   },
   "outputs": [],
   "source": [
    "###### Save GROUP classifier\n",
    "group_name = \"group_imputer\"\n",
    "group_dict = {}\n",
    "group_dict[\"predictors\"] = group_predictors\n",
    "group_dict[\"imputer\"] = group_imputer\n",
    "group_dict[\"scaler\"] = group_predictors_scaler\n",
    "\n",
    "dump(group_dict,data_folder+group_name+\".joblib\")\n",
    "\n",
    "###### Save FORMATION classifier\n",
    "formation_name = \"formation_imputer\"\n",
    "formation_dict = {}\n",
    "formation_dict[\"predictors\"] = formation_predictors\n",
    "formation_dict[\"imputer\"] = formation_imputer\n",
    "formation_dict[\"scaler\"] = formation_predictors_scaler\n",
    "\n",
    "dump(formation_dict,data_folder+formation_name+\".joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KEQfMXujMOPU"
   },
   "source": [
    "This is the end of data processing. We did null values imputation, categorical features encoding and numeric features scaling. "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOG8T+s/XXHKuKMZS8ZAVIG",
   "collapsed_sections": [
    "osxP7PEOGGlK"
   ],
   "name": "force_ml_modelisation_4.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:conda-leyanki_tf] *",
   "language": "python",
   "name": "conda-env-conda-leyanki_tf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
